{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"homework_4.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhvqmTDeiGLpxTme9Wm/4Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"12oCGyWBARB6"},"source":["# Deep Learning - Homework 04\n","\n","### Roberto Corti\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uC-UESICAAfj","executionInfo":{"status":"ok","timestamp":1618911648465,"user_tz":-120,"elapsed":28119,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}},"outputId":"9b3af01d-7b6a-40b6-fcf7-98a8e25bcb05"},"source":["### GOOGLE DRIVE \n","\n","from google.colab import drive\n","\n","folder_mount = '/content/drive' # Your Drive will be mounted on top of this path\n","\n","drive.mount(folder_mount)\n","\n","%cd drive/MyDrive/Università/DSSC/Secondo\\ Anno/Deep-Learning/homeworks/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Università/DSSC/Secondo Anno/Deep-Learning/homeworks\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cQIXqviNLKbF"},"source":["1. Now that you have all the tools to train an MLP with high performance on MNIST, try reaching 0-loss (or 100% accuracy) on the training data (with a small epsilon, e.g. 99.99% training performance -- don't worry if you overfit!). The implementation is completely up to you. You just need to keep it an MLP without using fancy layers (e.g., keep the Linear layers, don't use Conv1d or something like this, don't use attention). You are free to use any LR scheduler or optimizer, any one of batchnorm/groupnorm, regularization methods... If you use something we haven't seen during lectures, please motivate your choice and explain (as briefly as possible) how it works."]},{"cell_type":"code","metadata":{"id":"ilfa5LquBsh5","executionInfo":{"status":"ok","timestamp":1618911654381,"user_tz":-120,"elapsed":5311,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}}},"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import random\n","from torchvision.datasets import MNIST\n","import matplotlib.pyplot as plt\n","from torchvision.transforms import ToTensor, Normalize, Compose"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBe7DNakfdr4"},"source":["In order to reach 0-loss on the training data, as first decision that I have to make is related to the **mini-batch size**. \n","\n","Let's recap some useful information about the choice of this hyperparameter\n","\n","* It has been proven in practice that a large batch size will lead to poor generalization \n","\n","* Using a batch equal to the entire dataset guarantees convergence to the global optima of the objective function\n","\n","*  Small batch size have been empirically shown to have faster convergence, but it does not guarantee the convergence to the global optima\n","\n","\n","Since in this exercise our aim is not to generalize but to converge to the optimal choice of the weights of our network, I decide to use a mini batch size larger than the usual, equal to 512"]},{"cell_type":"code","metadata":{"id":"9-11xST3BpBf","executionInfo":{"status":"ok","timestamp":1618913092467,"user_tz":-120,"elapsed":1325,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}}},"source":["## Get MNIST data\n","'''\n","# https://stackoverflow.com/questions/66646604/http-error-503-service-unavailable-whan-trying-to-download-mnist-data\n","!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n","!tar -zxvf MNIST.tar.gz\n","\n","'''\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters \n","minibatch_size_train = 512\n","minibatch_size_test = 512\n","\n","\n","# Trasformations\n","transforms = Compose([\n","                      ToTensor(),\n","                      Normalize((0.1307,), (0.3081,))\n","                    ])\n","\n","# MNIST dataset \n","train_dataset = torchvision.datasets.MNIST(root='./data', \n","                                           train=True, \n","                                           transform=transforms,  \n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', \n","                                          train=False, \n","                                          transform=transforms)\n","\n","\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=minibatch_size_train, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=minibatch_size_test, \n","                                          shuffle=False)\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":267},"id":"_MHmsymuCG5J","executionInfo":{"status":"ok","timestamp":1618913094298,"user_tz":-120,"elapsed":2286,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}},"outputId":"2a3fa7b5-7101-4362-86cb-b54225ac9de7"},"source":["examples = iter(test_loader)\n","example_data, example_targets = examples.next()\n","\n","for i in range(6):\n","    plt.subplot(2,3,i+1)\n","    plt.imshow(example_data[i][0], cmap='gray')\n","plt.show()"],"execution_count":16,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 6 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"aoo_Nb9BnE7h"},"source":["The structure of the multi-layer perceptron that I chose for this problem is made up by only a single hidden layer but with a large number of neurons equal to 1024. Moreover, I observed that the use of a Batch-Normalization layer will help the model to converge faster\n","\n"]},{"cell_type":"code","metadata":{"id":"ghHAaQP4BgY6","executionInfo":{"status":"ok","timestamp":1618913334176,"user_tz":-120,"elapsed":1228,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}}},"source":["# Fully connected neural network with 1 hidden layer, inputsize=28*28, output\n","class MLP(nn.Module):\n","  '''\n","  Fully connected neural network with 1 hidden layer + Batch Normalization.\n","  Input size: 784\n","  Output size: 10\n","  '''\n","  def __init__(self):\n","    super().__init__()\n","    self.flat = nn.Flatten()\n","    self.h1 = nn.Linear(28*28, 1024)\n","    self.bout = nn.BatchNorm1d(num_features=1024)    \n","    self.out = nn.Linear(1024, 10)\n","\n","  def forward(self, X, activ_hidden=nn.functional.relu):\n","    out = self.flat(X)\n","    out = activ_hidden(self.h1(out))\n","    out = self.bout(out)\n","    out = self.out(out)\n","    return out"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M-bcUQ7vCNws","executionInfo":{"status":"ok","timestamp":1618913659466,"user_tz":-120,"elapsed":192548,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}},"outputId":"e92f1988-7bde-4a51-d95c-58099ae9963d"},"source":["# Model\n","model = MLP().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01) \n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n","\n","# Number of epochs\n","num_epochs = 15\n","\n","\n","# Train the model\n","n_total_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):  \n","        # origin shape: [512, 1, 28, 28]\n","        # resized: [512, 784]\n","        images = images.reshape(-1, 28*28).to(device)\n","        labels = labels.to(device)\n","        \n","        # Forward pass\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        \n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        if (i+1) % 50 == 0:\n","            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n","    \n","    scheduler.step()\n","\n","# Evaluate the model on train set\n","# In tthis phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    for images, labels in train_loader:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        # max returns (value ,index)\n","        _, predicted = torch.max(outputs.data, 1)\n","        n_samples += labels.size(0)\n","        n_correct += (predicted == labels).sum().item()\n","\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'\\n\\nAccuracy of the network on the train set: {acc:.3f} %')\n"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Epoch [1/15], Step [50/118], Loss: 0.1700\n","Epoch [1/15], Step [100/118], Loss: 0.1800\n","Epoch [2/15], Step [50/118], Loss: 0.1088\n","Epoch [2/15], Step [100/118], Loss: 0.0543\n","Epoch [3/15], Step [50/118], Loss: 0.0389\n","Epoch [3/15], Step [100/118], Loss: 0.0471\n","Epoch [4/15], Step [50/118], Loss: 0.0423\n","Epoch [4/15], Step [100/118], Loss: 0.0202\n","Epoch [5/15], Step [50/118], Loss: 0.0107\n","Epoch [5/15], Step [100/118], Loss: 0.0169\n","Epoch [6/15], Step [50/118], Loss: 0.0244\n","Epoch [6/15], Step [100/118], Loss: 0.0134\n","Epoch [7/15], Step [50/118], Loss: 0.0096\n","Epoch [7/15], Step [100/118], Loss: 0.0216\n","Epoch [8/15], Step [50/118], Loss: 0.0165\n","Epoch [8/15], Step [100/118], Loss: 0.0050\n","Epoch [9/15], Step [50/118], Loss: 0.0053\n","Epoch [9/15], Step [100/118], Loss: 0.0150\n","Epoch [10/15], Step [50/118], Loss: 0.0032\n","Epoch [10/15], Step [100/118], Loss: 0.0028\n","Epoch [11/15], Step [50/118], Loss: 0.0010\n","Epoch [11/15], Step [100/118], Loss: 0.0063\n","Epoch [12/15], Step [50/118], Loss: 0.0044\n","Epoch [12/15], Step [100/118], Loss: 0.0009\n","Epoch [13/15], Step [50/118], Loss: 0.0005\n","Epoch [13/15], Step [100/118], Loss: 0.0013\n","Epoch [14/15], Step [50/118], Loss: 0.0015\n","Epoch [14/15], Step [100/118], Loss: 0.0005\n","Epoch [15/15], Step [50/118], Loss: 0.0009\n","Epoch [15/15], Step [100/118], Loss: 0.0006\n","\n","\n","Accuracy of the network on the train set: 99.998 %\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LWKmefcsrKPL"},"source":["After 10 epochs the model is able to have a 99% accuracy on the training set."]},{"cell_type":"markdown","metadata":{"id":"i6g6dIM-LDov"},"source":["2. Try reaching 0-loss on the training data with permuted labels. Assess the model on the test data (without permuted labels) and comment."]},{"cell_type":"markdown","metadata":{"id":"e6XppAGOrgdt"},"source":["For this problem I will use a larger batch size equal to 1024.\n","\n","The reason of that is due to the fact that now data are randomly grouped and in order to get some information of this new decision boundary the network will require more data for each training step"]},{"cell_type":"code","metadata":{"id":"Nono3k76TzA0","executionInfo":{"status":"ok","timestamp":1618914174192,"user_tz":-120,"elapsed":966,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}}},"source":["# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters \n","minibatch_size_train = 1024\n","minibatch_size_test = 512\n","\n","\n","# Trasformations\n","transforms = Compose([\n","                      ToTensor(),\n","                      Normalize((0.1307,), (0.3081,))\n","                    ])\n","\n","# MNIST dataset \n","train_dataset = torchvision.datasets.MNIST(root='./data', \n","                                           train=True, \n","                                           transform=transforms,  \n","                                           download=True)\n","\n","test_dataset = torchvision.datasets.MNIST(root='./data', \n","                                          train=False, \n","                                          transform=transforms)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZ8J5lQPsTnZ"},"source":["To permute labels of the training set I followed these two steps:\n","\n","* Use the `shuffle` function (provided by the `random` package) on the index of the training set and save it into `shuffled_index`\n","\n","* Apply `shuffled_index` on the data member `target` of the train dataset class istance."]},{"cell_type":"code","metadata":{"id":"B59gH6UNLhZj","executionInfo":{"status":"ok","timestamp":1618914177449,"user_tz":-120,"elapsed":1078,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}}},"source":["index = [i for i in range(len(train_dataset))]\n","random.shuffle(index)\n","train_dataset.targets = train_dataset.targets[index]\n","\n","\n","# Data loader\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n","                                           batch_size=minibatch_size_train, \n","                                           shuffle=True)\n","\n","test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n","                                          batch_size=minibatch_size_test, \n","                                          shuffle=False)"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gxsvMIc62pVH"},"source":["Since this new classification problem seems to be more complex, I decide to add to the previous network a new hidden layer. The size of the hidden layers will be now 3000 and 1024."]},{"cell_type":"code","metadata":{"id":"GLKittY8Mu3W","executionInfo":{"status":"ok","timestamp":1618914180873,"user_tz":-120,"elapsed":1296,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}}},"source":["class MLP(nn.Module):\n","  '''\n","  Fully connected neural network with 2 hidden layer + Batch Normalization.\n","  Input size: 784\n","  Output size: 10\n","  '''\n","  def __init__(self):\n","    super().__init__()\n","    self.layers = nn.Sequential(\n","        nn.Linear(784, 3000),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(3000),\n","        nn.Linear(3000, 1024),\n","        nn.ReLU(),\n","        nn.BatchNorm1d(1024),\n","        nn.Linear(1024,10)\n","    )\n","  def forward(self, x):\n","    return (self.layers(x.view(-1,784)))"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kZqpIIKhOuRS","executionInfo":{"status":"ok","timestamp":1618915602123,"user_tz":-120,"elapsed":612562,"user":{"displayName":"Roberto Corti","photoUrl":"https://lh4.googleusercontent.com/-KaiJHEP6Eps/AAAAAAAAAAI/AAAAAAAAABU/y4Yv-P85NuU/s64/photo.jpg","userId":"08099351609548175475"}},"outputId":"9f19c824-d8a8-408d-f388-861d849280e7"},"source":["# Model\n","model = MLP().to(device)\n","\n","# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001) \n","scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n","\n","# Number of epochs\n","num_epochs = 50\n","\n","\n","# Train the model\n","n_total_steps = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, labels) in enumerate(train_loader):\n","      # origin shape: [512, 1, 28, 28]\n","      # resized: [512, 784]\n","      images = images.reshape(-1, 28*28).to(device)\n","      labels = labels.to(device)\n","      \n","      # Forward pass\n","      outputs = model(images)\n","      loss = criterion(outputs, labels)\n","      \n","      # Backward and optimize\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","      \n","      #print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n","      if (i+1) % 50 == 0:\n","          print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n","\n","    scheduler.step()\n","\n","# Test the model\n","# In test phase, we don't need to compute gradients (for memory efficiency)\n","with torch.no_grad():\n","    n_correct = 0\n","    n_samples = 0\n","    for i, (images, labels) in enumerate(train_loader):\n","      if i == 0:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        # max returns (value ,index)\n","        _, predicted = torch.max(outputs.data, 1)\n","        n_samples += labels.size(0)\n","        n_correct += (predicted == labels).sum().item()\n","\n","    acc = 100.0 * n_correct / n_samples\n","    print(f'\\n\\nAccuracy of the network on the train set: {acc:.3f} %')"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Epoch [1/50], Step [50/59], Loss: 2.3314\n","Epoch [2/50], Step [50/59], Loss: 2.3031\n","Epoch [3/50], Step [50/59], Loss: 2.2913\n","Epoch [4/50], Step [50/59], Loss: 2.2774\n","Epoch [5/50], Step [50/59], Loss: 2.2711\n","Epoch [6/50], Step [50/59], Loss: 2.2662\n","Epoch [7/50], Step [50/59], Loss: 2.2329\n","Epoch [8/50], Step [50/59], Loss: 2.1777\n","Epoch [9/50], Step [50/59], Loss: 2.1185\n","Epoch [10/50], Step [50/59], Loss: 2.1078\n","Epoch [11/50], Step [50/59], Loss: 2.0114\n","Epoch [12/50], Step [50/59], Loss: 1.9550\n","Epoch [13/50], Step [50/59], Loss: 1.8718\n","Epoch [14/50], Step [50/59], Loss: 1.7192\n","Epoch [15/50], Step [50/59], Loss: 1.5747\n","Epoch [16/50], Step [50/59], Loss: 1.3472\n","Epoch [17/50], Step [50/59], Loss: 1.2216\n","Epoch [18/50], Step [50/59], Loss: 0.9697\n","Epoch [19/50], Step [50/59], Loss: 0.8361\n","Epoch [20/50], Step [50/59], Loss: 0.6737\n","Epoch [21/50], Step [50/59], Loss: 0.5443\n","Epoch [22/50], Step [50/59], Loss: 0.4253\n","Epoch [23/50], Step [50/59], Loss: 0.3378\n","Epoch [24/50], Step [50/59], Loss: 0.2975\n","Epoch [25/50], Step [50/59], Loss: 0.2557\n","Epoch [26/50], Step [50/59], Loss: 0.2273\n","Epoch [27/50], Step [50/59], Loss: 0.2053\n","Epoch [28/50], Step [50/59], Loss: 0.1941\n","Epoch [29/50], Step [50/59], Loss: 0.1718\n","Epoch [30/50], Step [50/59], Loss: 0.1460\n","Epoch [31/50], Step [50/59], Loss: 0.1485\n","Epoch [32/50], Step [50/59], Loss: 0.1351\n","Epoch [33/50], Step [50/59], Loss: 0.1208\n","Epoch [34/50], Step [50/59], Loss: 0.1042\n","Epoch [35/50], Step [50/59], Loss: 0.0945\n","Epoch [36/50], Step [50/59], Loss: 0.0810\n","Epoch [37/50], Step [50/59], Loss: 0.0932\n","Epoch [38/50], Step [50/59], Loss: 0.0701\n","Epoch [39/50], Step [50/59], Loss: 0.0659\n","Epoch [40/50], Step [50/59], Loss: 0.0501\n","Epoch [41/50], Step [50/59], Loss: 0.0461\n","Epoch [42/50], Step [50/59], Loss: 0.0475\n","Epoch [43/50], Step [50/59], Loss: 0.0416\n","Epoch [44/50], Step [50/59], Loss: 0.0326\n","Epoch [45/50], Step [50/59], Loss: 0.0272\n","Epoch [46/50], Step [50/59], Loss: 0.0317\n","Epoch [47/50], Step [50/59], Loss: 0.0302\n","Epoch [48/50], Step [50/59], Loss: 0.0239\n","Epoch [49/50], Step [50/59], Loss: 0.0210\n","Epoch [50/50], Step [50/59], Loss: 0.0196\n","\n","\n","Accuracy of the network on the train set: 100.000 %\n"],"name":"stdout"}]}]}